{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\ai\\lib\\site-packages\\scipy\\__init__.py:173: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.load('D:/Dropbox/AICleansing_ver2/2.ProcessedData/train_mimic_orgscale.npy')\n",
    "# TrData = np.load('D:/Dropbox/AICleansing_ver2/2.ProcessedData/train_mimic_orgscale.npy')\n",
    "# ValData = np.load('D:/Dropbox/AICleansing_ver2/2.ProcessedData/valid_vitaldb_orgscale.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(283380, 3000) (70844, 3000)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(Data)\n",
    "Data_len = len(Data)\n",
    "ValData = Data[:len(Data)//5]\n",
    "TrData = Data[len(Data)//5:]\n",
    "print(TrData.shape, ValData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver2\n",
    "\n",
    "TrDataFrame = tf.signal.frame(TrData.astype('float32'), 1, 1).numpy()\n",
    "ValDataFrame = tf.signal.frame(ValData.astype('float32'), 1, 1).numpy()\n",
    "\n",
    "# np.random.shuffle(TrDataFrame)\n",
    "# np.random.shuffle(ValDataFrame)\n",
    "\n",
    "TrMask = np.random.choice([0,1], size=TrDataFrame.shape, p=[0.1,0.9])\n",
    "ValMask = np.random.choice([0,1], size=ValDataFrame.shape, p=[0.1,0.9])\n",
    "\n",
    "Tr_X = TrDataFrame.copy()\n",
    "Tr_Y = (TrDataFrame - 20.0) / (220.0 - 20.0)\n",
    "# 평균 80, 표준 편차 25인 정규 분포에서 값을 뽑아서 채울 배열 생성\n",
    "random_values = np.random.normal(loc=80, scale=25, size=TrDataFrame.shape)\n",
    "# TrMask가 1인 위치에 뽑은 값을 할당\n",
    "Tr_X[TrMask == 0] = random_values[TrMask == 0]\n",
    "Tr_X = (Tr_X - 20.0) / (220.0 - 20.0)\n",
    "\n",
    "TrMask[:,-10:,:] = 0\n",
    "Tr_X[:,-10:,:] = Tr_X[:,-10:,:] + np.random.normal(loc=0.0, scale=0.05, size=Tr_X[:,-10:,:].shape)\n",
    "\n",
    "Tr_X = np.clip(Tr_X, 0.0, 1.0)\n",
    "\n",
    "Val_X = ValDataFrame.copy()\n",
    "Val_Y = (ValDataFrame - 20.0) / (220.0 - 20.0)\n",
    "# 평균 80, 표준 편차 25인 정규 분포에서 값을 뽑아서 채울 배열 생성\n",
    "random_values = np.random.normal(loc=80, scale=25, size=ValDataFrame.shape)\n",
    "# TrMask가 1인 위치에 뽑은 값을 할당\n",
    "Val_X[ValMask == 0] = random_values[ValMask == 0]\n",
    "Val_X = (Val_X - 20.0) / (220.0 - 20.0)\n",
    "\n",
    "ValMask[:,-10:,:] = 0\n",
    "Val_X[:,-10:,:] = Val_X[:,-10:,:] + np.random.normal(loc=0.0, scale=0.05, size=Val_X[:,-10:,:].shape)\n",
    "\n",
    "Val_X = np.clip(Val_X, 0.0, 1.0)\n",
    "\n",
    "del random_values\n",
    "del TrDataFrame\n",
    "del ValDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Length = Tr_X.shape[1]\n",
    "OrigDim = Tr_X.shape[-1]\n",
    "\n",
    "\n",
    "NumLayers=2\n",
    "EmbedDim = 64\n",
    "NumHead = 1\n",
    "DimFC = 200\n",
    "BottleneckSize = EmbedDim // 8\n",
    "Groups = NumHead * 2\n",
    "HeadDim = EmbedDim // NumHead\n",
    "NumLayers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedBottleneckBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,  out_channel=64, bottleneck=BottleneckSize, kernel_size=15, dilation=1, groups=Groups, firstlayergroups=None):\n",
    "        super(DilatedBottleneckBlock, self).__init__()\n",
    "        self.firstlayergroups = firstlayergroups\n",
    "\n",
    "        # Bottle\n",
    "        self.bottle = tf.keras.layers.Conv1D(bottleneck, kernel_size=1, groups=groups)\n",
    "        \n",
    "        # ReLU\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "        # BatchNorm\n",
    "        self.bn = tf.keras.layers.BatchNormalization(center=True, scale=True)\n",
    "\n",
    "        # Dilated Conv\n",
    "        dilation_padding = (kernel_size - 1) // 2 * dilation\n",
    "        if firstlayergroups:\n",
    "            self.dilated_conv = tf.keras.layers.Conv1D(out_channel, kernel_size, dilation_rate=dilation, padding='same', groups=firstlayergroups)\n",
    "        else:\n",
    "            self.dilated_conv = tf.keras.layers.Conv1D(out_channel, kernel_size, dilation_rate=dilation, padding='same', groups=groups)\n",
    "\n",
    "    def call(self, x):\n",
    "        bottle_out = self.bottle(x)\n",
    "        conv_out = self.dilated_conv(bottle_out)\n",
    "        \n",
    "        if self.firstlayergroups:\n",
    "            return self.bn(self.relu(conv_out) + tf.tile(x, [1, 1, 2]))\n",
    "        else:\n",
    "            return self.bn(self.relu(conv_out) + x)\n",
    "\n",
    "class DilatedBottleneckNet(tf.keras.Model):\n",
    "    def __init__(self,  out_channel=256, bottleneck=BottleneckSize, kernel_size=15, dilation=50, groups=Groups):\n",
    "        super(DilatedBottleneckNet, self).__init__()\n",
    "\n",
    "        self.layer0 = DilatedBottleneckBlock( out_channel * 2, bottleneck * 2, kernel_size, dilation, 1, firstlayergroups=groups)\n",
    "        self.layer1 = DilatedBottleneckBlock( out_channel * 2, bottleneck * 2, kernel_size, dilation * 2, groups)\n",
    "        self.layer2 = DilatedBottleneckBlock( out_channel * 2, bottleneck * 2, kernel_size, dilation * 4, groups)\n",
    "        self.layer3 = DilatedBottleneckBlock( out_channel * 2, bottleneck * 2, kernel_size, dilation * 8, groups)\n",
    "        self.layer4 = DilatedBottleneckBlock( out_channel * 2, bottleneck * 2, kernel_size, dilation * 16, groups)\n",
    "        self.layer5 = DilatedBottleneckBlock( out_channel * 2, bottleneck * 2, kernel_size, dilation * 32, groups)\n",
    "\n",
    "    def call(self, x):\n",
    "            x0 = self.layer0(x)\n",
    "            x1 = self.layer1(x0)\n",
    "            x2 = self.layer2(x1)\n",
    "            x3 = self.layer3(x2)\n",
    "            x4 = self.layer4(x3)\n",
    "            x5 = self.layer5(x4)\n",
    "            \n",
    "            return x5 # return shape (batch, length, embed)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)# (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, bottleneck=BottleneckSize, groups=Groups, rate=0.1, t_len=-1):\n",
    "        super(CustomAttention, self).__init__()\n",
    "    \n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.scaling = num_heads ** -0.5\n",
    "        self.t_len = t_len \n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.DBN = DilatedBottleneckNet(out_channel =d_model , bottleneck = bottleneck, groups=groups)\n",
    "        \n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        self.dr = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        \n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size,  self.t_len, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    \n",
    "    def call(self,  x, training, mask):\n",
    "        \n",
    "        \n",
    "        \n",
    "        q, k =  tf.split(self.DBN(x), 2, axis=-1)\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        v = self.wv(x)\n",
    "\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # Scaling q\n",
    "        q = q * self.scaling\n",
    "\n",
    "        # Computing the batch matrix multiplication\n",
    "        AttOutWeights =  tf.linalg.matmul(q, k, transpose_b=True)\n",
    "        \n",
    "        # Masking before normalization for proper attention distribution\n",
    "        Mask_repeated = tf.tile(mask[:, None], [1, self.num_heads, 1, 1])\n",
    "        masked_out_weights = tf.multiply(AttOutWeights, Mask_repeated) \n",
    "        \n",
    "        # Subtracting max value for numerical stability before taking exponential\n",
    "        max_vals = tf.math.reduce_max(masked_out_weights, axis=-1, keepdims=True)\n",
    "        AttOutputWeights = tf.exp(masked_out_weights - max_vals) \n",
    "        \n",
    "        # Applying normalization\n",
    "        sum_vals = tf.math.reduce_sum(AttOutputWeights, axis=-1, keepdims=True)\n",
    "        AttOutputWeights /= sum_vals\n",
    "        \n",
    "        # Applying dropout\n",
    "        AttOutputWeights = self.dr(AttOutputWeights)\n",
    "\n",
    "        \n",
    "        # Computing attention output using batched matrix multiplication\n",
    "        AttOutput = tf.linalg.matmul(AttOutputWeights, v)\n",
    "\n",
    "        # Reshaping and transposing tensors\n",
    "        AttOutput = tf.reshape(tf.transpose(AttOutput, perm=[0, 2, 1, 3]), [-1, self.t_len, self.d_model])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention( q, k, v, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention,  (-1, self.t_len, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        '''\n",
    "        \n",
    "        return AttOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, bottleneck=BottleneckSize, groups=Groups,  rate=0.1, t_len=-1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        \n",
    "                \n",
    "        self.catt = CustomAttention(d_model, num_heads, bottleneck=bottleneck, t_len=t_len)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        \n",
    "        attn_output = self.catt(x, training, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "            \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, bottleneck=BottleneckSize, groups=Groups,  rate=0.1, t_len=-1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.convembed = tf.keras.layers.Conv1D(filters=d_model, kernel_size=11, strides=1, padding='same', dilation_rate=1)\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "      \n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate=rate, t_len=t_len)  for _ in range(num_layers)]\n",
    "        \n",
    "\n",
    "        #self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.convembed(x)\n",
    "        x = self.bn(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "     \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "        \n",
    "        \n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# ModelCheckpoint 설정\n",
    "checkpoint_filepath = './results/BDC_rightedge_mask_only_mimic.hdf5'  # 저장할 파일 경로 및 이름\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',  # 검증 데이터의 loss를 기준으로 함\n",
    "    mode='min',  # loss의 최솟값을 모니터링\n",
    "    save_best_only=True  # 가장 낮은 loss 값을 가질 때만 저장\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "InpLayer = tf.keras.layers.Input((Length, 1))\n",
    "InpMask  = tf.keras.layers.Input((Length, 1))\n",
    "EmbedOut = Encoder(num_layers = NumLayers, d_model = EmbedDim, num_heads = NumHead, dff = DimFC, t_len=Length)(InpLayer, True, InpMask)\n",
    "\n",
    "# After Encoder\n",
    "Projection = Conv1D(filters=OrigDim, kernel_size=11, strides=1, padding='same', dilation_rate=1)(EmbedOut)\n",
    "#Projection= Activation('sigmoid')(Projection)\n",
    "\n",
    "learning_rate = 0.00001  # replace this with your desired learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "BDC = Model([InpLayer,InpMask ], Projection)\n",
    "BDC.compile(loss='mse', optimizer = optimizer, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 0.0595 - val_loss: 0.0069\n",
      "Epoch 2/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 3/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 0.0011 - val_loss: 9.6499e-04\n",
      "Epoch 5/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 8.1492e-04 - val_loss: 6.9623e-04\n",
      "Epoch 6/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 6.4386e-04 - val_loss: 5.5289e-04\n",
      "Epoch 7/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 5.1484e-04 - val_loss: 4.4233e-04\n",
      "Epoch 8/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 4.0957e-04 - val_loss: 3.5504e-04\n",
      "Epoch 9/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 3.2939e-04 - val_loss: 2.8645e-04\n",
      "Epoch 10/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.6987e-04 - val_loss: 2.4404e-04\n",
      "Epoch 11/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.2545e-04 - val_loss: 2.5970e-04\n",
      "Epoch 12/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.9271e-04 - val_loss: 1.9387e-04\n",
      "Epoch 13/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6740e-04 - val_loss: 1.7908e-04\n",
      "Epoch 14/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.4876e-04 - val_loss: 1.3474e-04\n",
      "Epoch 15/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.3389e-04 - val_loss: 1.2253e-04\n",
      "Epoch 16/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.2185e-04 - val_loss: 1.1035e-04\n",
      "Epoch 17/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.1260e-04 - val_loss: 1.0938e-04\n",
      "Epoch 18/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.0440e-04 - val_loss: 1.0875e-04\n",
      "Epoch 19/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 9.6983e-05 - val_loss: 1.0828e-04\n",
      "Epoch 20/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 9.0914e-05 - val_loss: 8.2696e-05\n",
      "Epoch 21/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 8.5563e-05 - val_loss: 7.8222e-05\n",
      "Epoch 22/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 8.0797e-05 - val_loss: 7.5672e-05\n",
      "Epoch 23/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 7.6970e-05 - val_loss: 7.0964e-05\n",
      "Epoch 24/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 7.2831e-05 - val_loss: 8.9322e-05\n",
      "Epoch 25/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 6.9793e-05 - val_loss: 6.3933e-05\n",
      "Epoch 26/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 6.6833e-05 - val_loss: 6.6715e-05\n",
      "Epoch 27/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 6.4316e-05 - val_loss: 5.8238e-05\n",
      "Epoch 28/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 6.1826e-05 - val_loss: 5.7810e-05\n",
      "Epoch 29/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 5.9197e-05 - val_loss: 5.3989e-05\n",
      "Epoch 30/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 5.7396e-05 - val_loss: 6.0283e-05\n",
      "Epoch 31/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 5.5000e-05 - val_loss: 6.5575e-05\n",
      "Epoch 32/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 5.3857e-05 - val_loss: 4.9486e-05\n",
      "Epoch 33/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 5.1984e-05 - val_loss: 4.7333e-05\n",
      "Epoch 34/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 4.9727e-05 - val_loss: 4.5322e-05\n",
      "Epoch 35/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 4.8868e-05 - val_loss: 4.4339e-05\n",
      "Epoch 36/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 4.6914e-05 - val_loss: 4.2444e-05\n",
      "Epoch 37/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 4.6077e-05 - val_loss: 6.2551e-05\n",
      "Epoch 38/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 4.4609e-05 - val_loss: 4.0235e-05\n",
      "Epoch 39/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 4.3411e-05 - val_loss: 4.2017e-05\n",
      "Epoch 40/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 4.2601e-05 - val_loss: 4.6273e-05\n",
      "Epoch 41/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 4.1424e-05 - val_loss: 5.5768e-05\n",
      "Epoch 42/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 4.0127e-05 - val_loss: 3.8811e-05\n",
      "Epoch 43/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 3.9649e-05 - val_loss: 4.0214e-05\n",
      "Epoch 44/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.8634e-05 - val_loss: 4.2527e-05\n",
      "Epoch 45/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.7825e-05 - val_loss: 3.4958e-05\n",
      "Epoch 46/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 3.6914e-05 - val_loss: 3.5585e-05\n",
      "Epoch 47/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 3.6277e-05 - val_loss: 3.3470e-05\n",
      "Epoch 48/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 3.5405e-05 - val_loss: 4.1493e-05\n",
      "Epoch 49/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 3.4561e-05 - val_loss: 3.2270e-05\n",
      "Epoch 50/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.4236e-05 - val_loss: 3.0550e-05\n",
      "Epoch 51/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 3.3192e-05 - val_loss: 2.9851e-05\n",
      "Epoch 52/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.3000e-05 - val_loss: 3.7850e-05\n",
      "Epoch 53/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 3.2424e-05 - val_loss: 3.3184e-05\n",
      "Epoch 54/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 3.2094e-05 - val_loss: 3.0601e-05\n",
      "Epoch 55/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.1234e-05 - val_loss: 3.9510e-05\n",
      "Epoch 56/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.1115e-05 - val_loss: 3.0052e-05\n",
      "Epoch 57/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 3.0276e-05 - val_loss: 2.7998e-05\n",
      "Epoch 58/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.9856e-05 - val_loss: 2.7224e-05\n",
      "Epoch 59/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.9450e-05 - val_loss: 3.0109e-05\n",
      "Epoch 60/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.8987e-05 - val_loss: 3.9752e-05\n",
      "Epoch 61/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.8574e-05 - val_loss: 2.5603e-05\n",
      "Epoch 62/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.8410e-05 - val_loss: 2.9455e-05\n",
      "Epoch 63/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 2.7821e-05 - val_loss: 3.4023e-05\n",
      "Epoch 64/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.7774e-05 - val_loss: 2.4592e-05\n",
      "Epoch 65/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.7398e-05 - val_loss: 2.6949e-05\n",
      "Epoch 66/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.6989e-05 - val_loss: 2.5458e-05\n",
      "Epoch 67/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.6320e-05 - val_loss: 2.6978e-05\n",
      "Epoch 68/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.6236e-05 - val_loss: 3.4313e-05\n",
      "Epoch 69/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.5568e-05 - val_loss: 2.3555e-05\n",
      "Epoch 70/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.5401e-05 - val_loss: 2.4600e-05\n",
      "Epoch 71/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.5003e-05 - val_loss: 2.6647e-05\n",
      "Epoch 72/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.4651e-05 - val_loss: 2.2116e-05\n",
      "Epoch 73/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.4477e-05 - val_loss: 2.2363e-05\n",
      "Epoch 74/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.4501e-05 - val_loss: 3.0028e-05\n",
      "Epoch 75/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.4005e-05 - val_loss: 2.4755e-05\n",
      "Epoch 76/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.3847e-05 - val_loss: 2.1031e-05\n",
      "Epoch 77/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.3461e-05 - val_loss: 2.1778e-05\n",
      "Epoch 78/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.3343e-05 - val_loss: 2.4738e-05\n",
      "Epoch 79/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.3226e-05 - val_loss: 2.1227e-05\n",
      "Epoch 80/10000\n",
      "9446/9446 [==============================] - 2519s 267ms/step - loss: 2.2515e-05 - val_loss: 2.3871e-05\n",
      "Epoch 81/10000\n",
      "9446/9446 [==============================] - 2519s 267ms/step - loss: 2.2525e-05 - val_loss: 2.2624e-05\n",
      "Epoch 82/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.2259e-05 - val_loss: 2.2042e-05\n",
      "Epoch 83/10000\n",
      "9446/9446 [==============================] - 2519s 267ms/step - loss: 2.2029e-05 - val_loss: 1.9786e-05\n",
      "Epoch 84/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.1969e-05 - val_loss: 1.9458e-05\n",
      "Epoch 85/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.1743e-05 - val_loss: 1.9713e-05\n",
      "Epoch 86/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.1533e-05 - val_loss: 1.9589e-05\n",
      "Epoch 87/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.1094e-05 - val_loss: 1.8837e-05\n",
      "Epoch 88/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.1103e-05 - val_loss: 1.8652e-05\n",
      "Epoch 89/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 2.1062e-05 - val_loss: 1.8547e-05\n",
      "Epoch 90/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.0606e-05 - val_loss: 2.7249e-05\n",
      "Epoch 91/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.0608e-05 - val_loss: 1.8948e-05\n",
      "Epoch 92/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 2.0380e-05 - val_loss: 1.9712e-05\n",
      "Epoch 93/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.0042e-05 - val_loss: 2.7843e-05\n",
      "Epoch 94/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 2.0208e-05 - val_loss: 1.7873e-05\n",
      "Epoch 95/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.9887e-05 - val_loss: 2.0475e-05\n",
      "Epoch 96/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.9899e-05 - val_loss: 1.8336e-05\n",
      "Epoch 97/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.9760e-05 - val_loss: 2.0409e-05\n",
      "Epoch 98/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.9267e-05 - val_loss: 1.7119e-05\n",
      "Epoch 99/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.9278e-05 - val_loss: 2.1583e-05\n",
      "Epoch 100/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.9216e-05 - val_loss: 2.0683e-05\n",
      "Epoch 101/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.8949e-05 - val_loss: 1.7643e-05\n",
      "Epoch 102/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.8792e-05 - val_loss: 1.6698e-05\n",
      "Epoch 103/10000\n",
      "9446/9446 [==============================] - 2519s 267ms/step - loss: 1.8694e-05 - val_loss: 1.6603e-05\n",
      "Epoch 104/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.8535e-05 - val_loss: 1.6477e-05\n",
      "Epoch 105/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.8224e-05 - val_loss: 2.0645e-05\n",
      "Epoch 106/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.8200e-05 - val_loss: 1.7441e-05\n",
      "Epoch 107/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.8184e-05 - val_loss: 1.7806e-05\n",
      "Epoch 108/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.7925e-05 - val_loss: 1.6790e-05\n",
      "Epoch 109/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.7862e-05 - val_loss: 1.6167e-05\n",
      "Epoch 110/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.7584e-05 - val_loss: 1.6864e-05\n",
      "Epoch 111/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.7721e-05 - val_loss: 1.6742e-05\n",
      "Epoch 112/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.7524e-05 - val_loss: 1.5597e-05\n",
      "Epoch 113/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.7204e-05 - val_loss: 1.6271e-05\n",
      "Epoch 114/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.7205e-05 - val_loss: 1.6282e-05\n",
      "Epoch 115/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.7285e-05 - val_loss: 1.6282e-05\n",
      "Epoch 116/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.7058e-05 - val_loss: 1.7903e-05\n",
      "Epoch 117/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6822e-05 - val_loss: 1.7191e-05\n",
      "Epoch 118/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6721e-05 - val_loss: 1.6292e-05\n",
      "Epoch 119/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6751e-05 - val_loss: 1.4792e-05\n",
      "Epoch 120/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.6614e-05 - val_loss: 1.6817e-05\n",
      "Epoch 121/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.6522e-05 - val_loss: 1.5272e-05\n",
      "Epoch 122/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6394e-05 - val_loss: 1.4863e-05\n",
      "Epoch 123/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.6291e-05 - val_loss: 1.5982e-05\n",
      "Epoch 124/10000\n",
      "9446/9446 [==============================] - 2521s 267ms/step - loss: 1.6309e-05 - val_loss: 1.4667e-05\n",
      "Epoch 125/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6044e-05 - val_loss: 1.4587e-05\n",
      "Epoch 126/10000\n",
      "9446/9446 [==============================] - 2520s 267ms/step - loss: 1.6052e-05 - val_loss: 1.4450e-05\n",
      "Epoch 127/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.6080e-05 - val_loss: 1.5775e-05\n",
      "Epoch 128/10000\n",
      "9446/9446 [==============================] - 2522s 267ms/step - loss: 1.5734e-05 - val_loss: 1.4446e-05\n",
      "Epoch 129/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.5777e-05 - val_loss: 1.4468e-05\n",
      "Epoch 130/10000\n",
      "9446/9446 [==============================] - 2527s 267ms/step - loss: 1.5470e-05 - val_loss: 1.5710e-05\n",
      "Epoch 131/10000\n",
      "9446/9446 [==============================] - 2527s 268ms/step - loss: 1.5575e-05 - val_loss: 1.4363e-05\n",
      "Epoch 132/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.5458e-05 - val_loss: 1.7761e-05\n",
      "Epoch 133/10000\n",
      "9446/9446 [==============================] - 2527s 268ms/step - loss: 1.5259e-05 - val_loss: 1.6264e-05\n",
      "Epoch 134/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.5217e-05 - val_loss: 1.4219e-05\n",
      "Epoch 135/10000\n",
      "9446/9446 [==============================] - 2527s 268ms/step - loss: 1.5090e-05 - val_loss: 1.3821e-05\n",
      "Epoch 136/10000\n",
      "9446/9446 [==============================] - 2527s 267ms/step - loss: 1.5055e-05 - val_loss: 1.4079e-05\n",
      "Epoch 137/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.4969e-05 - val_loss: 1.3354e-05\n",
      "Epoch 138/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.4869e-05 - val_loss: 1.4047e-05\n",
      "Epoch 139/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.4837e-05 - val_loss: 1.3815e-05\n",
      "Epoch 140/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.4674e-05 - val_loss: 1.3096e-05\n",
      "Epoch 141/10000\n",
      "9446/9446 [==============================] - 2523s 267ms/step - loss: 1.4624e-05 - val_loss: 1.3078e-05\n",
      "Epoch 142/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.4587e-05 - val_loss: 1.4423e-05\n",
      "Epoch 143/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.4531e-05 - val_loss: 1.6535e-05\n",
      "Epoch 144/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.4367e-05 - val_loss: 1.5816e-05\n",
      "Epoch 145/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.4400e-05 - val_loss: 1.7000e-05\n",
      "Epoch 146/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.4154e-05 - val_loss: 1.3447e-05\n",
      "Epoch 147/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.4179e-05 - val_loss: 1.3290e-05\n",
      "Epoch 148/10000\n",
      "9446/9446 [==============================] - 2524s 267ms/step - loss: 1.4157e-05 - val_loss: 1.2651e-05\n",
      "Epoch 149/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.4048e-05 - val_loss: 1.2470e-05\n",
      "Epoch 150/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3947e-05 - val_loss: 1.5788e-05\n",
      "Epoch 151/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3839e-05 - val_loss: 1.5949e-05\n",
      "Epoch 152/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3855e-05 - val_loss: 1.3028e-05\n",
      "Epoch 153/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3739e-05 - val_loss: 1.4804e-05\n",
      "Epoch 154/10000\n",
      "9446/9446 [==============================] - 2527s 268ms/step - loss: 1.3633e-05 - val_loss: 1.2682e-05\n",
      "Epoch 155/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3642e-05 - val_loss: 1.2209e-05\n",
      "Epoch 156/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.3530e-05 - val_loss: 1.2207e-05\n",
      "Epoch 157/10000\n",
      "9446/9446 [==============================] - 2525s 267ms/step - loss: 1.3617e-05 - val_loss: 1.4675e-05\n",
      "Epoch 158/10000\n",
      "9446/9446 [==============================] - 2527s 268ms/step - loss: 1.3351e-05 - val_loss: 1.1981e-05\n",
      "Epoch 159/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3332e-05 - val_loss: 1.3688e-05\n",
      "Epoch 160/10000\n",
      "9446/9446 [==============================] - 2526s 267ms/step - loss: 1.3247e-05 - val_loss: 1.2653e-05\n",
      "Epoch 161/10000\n",
      " 154/9446 [..............................] - ETA: 38:14 - loss: 1.2333e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mBDC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTr_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrMask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTr_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mVal_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mValMask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVal_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1105\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1107\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 454\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 296\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(callback, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m numpy_logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Only convert once.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1020\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1083\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1084\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py:510\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    509\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 510\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1071\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \n\u001b[0;32m   1050\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1071\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1037\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1036\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1038\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(core\u001b[38;5;241m.\u001b[39m_status_to_exception(e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmessage), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BDC.fit([Tr_X, TrMask], Tr_Y, validation_data=([Val_X, ValMask], Val_Y), batch_size=30, verbose=1, shuffle=True, epochs=10000, callbacks=[model_checkpoint_callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BottleneckSize, Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trans_qkz (tensor, dims):\n",
    "    tensor = tf.transpose(tensor, perm=[2, 0, 1])\n",
    "    tensor = tf.reshape(tensor, dims)\n",
    "    return tf.transpose(tensor, perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 500, 128), dtype=tf.float32, name=None), name='tf.split_3/split:0', description=\"created by layer 'tf.split_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 500, 128), dtype=tf.float32, name=None), name='tf.split_3/split:1', description=\"created by layer 'tf.split_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 500, 128), dtype=tf.float32, name=None), name='dense_5/BiasAdd:0', description=\"created by layer 'dense_5'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(400, 500, 32) dtype=float32 (created by layer 'tf.compat.v1.transpose_25')>,\n",
       " <KerasTensor: shape=(400, 500, 32) dtype=float32 (created by layer 'tf.compat.v1.transpose_27')>,\n",
       " <KerasTensor: shape=(400, 500, 32) dtype=float32 (created by layer 'tf.compat.v1.transpose_29')>,\n",
       " <KerasTensor: shape=() dtype=int32 inferred_value=[500] (created by layer 'tf.__operators__.getitem_2')>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTModel = DilatedBottleneckNet(out_channel =EmbedDim , bottleneck = BottleneckSize, groups=Groups)\n",
    "q, k =  tf.split(BTModel(Embed), 2, axis=-1)\n",
    "v = tf.keras.layers.Dense(EmbedDim, use_bias=True)(Embed)\n",
    "\n",
    "print(q)\n",
    "print(k)\n",
    "print(v)\n",
    "\n",
    "q =  tf.transpose(q, (1,2,0)) # [batch size, channel, length]\n",
    "k =  tf.transpose(k, (1,2,0)) # [batch size, channel, length] \n",
    "v =  tf.transpose(v, (1,0,2)) # [batch size, length, channel]\n",
    "\n",
    "\n",
    "\n",
    "#input before the view() should be [len, bs, channel]\n",
    "bsz = 100\n",
    "q = Trans_qkz (q, [Length, bsz * NumHead, HeadDim])    \n",
    "k = Trans_qkz (k, [Length, bsz * NumHead, HeadDim])    \n",
    "v = Trans_qkz (v, [Length, bsz * NumHead, HeadDim])  \n",
    "#output should be [bsz * num_heads, len, head_dim]\n",
    "\n",
    "SrcLen = tf.shape(k)[1]\n",
    "\n",
    "q,k, v, SrcLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 500, 256) dtype=float32 (created by layer 'tf.split')>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 43, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_encoder_layer_output = sample_encoder_layer( tf.random.uniform((20, 43, 512)), False, None)\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DilatedBottleneckBlock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2bad720528f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mDilatedBottleneckBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channel\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottleneck\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstlayergroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DilatedBottleneckBlock' is not defined"
     ]
    }
   ],
   "source": [
    "in_channel=256\n",
    "out_channel=256\n",
    "bottleneck=32\n",
    "kernel_size=15\n",
    "dilation=1\n",
    "groups=2\n",
    "DilatedBottleneckBlock(in_channel, out_channel * 2, bottleneck * 2, kernel_size, dilation, 1, firstlayergroups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, orig_dim=12, embed_dim=32, **kwargs):\n",
    "        super(ConvEmbedding, self).__init__(**kwargs)\n",
    "\n",
    "        self.embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv1D(filters=embed_dim, kernel_size=11, strides=1, padding='same', dilation_rate=1, input_shape=(None, orig_dim)),\n",
    "            tf.keras.layers.BatchNormalization(axis=-1, trainable=True, center=True, scale=True, momentum=0.99, epsilon=0.001),\n",
    "            tf.keras.layers.ReLU()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # Current shape (batch_size, length, channels)\n",
    "        #x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        x1 = self.embedding(x)\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bottleneck=32\n",
    "kernel_size=15\n",
    "dilation=1\n",
    "groups=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_ppg_test = np.load('./mimic_ppg_test.npy')\n",
    "\n",
    "# shape [batch_size, embed_dim, length]\n",
    "Length = mimic_ppg_test.shape[1]\n",
    "OrigDim = mimic_ppg_test.shape[-1]\n",
    "EmbedDim = 100\n",
    "NumHead = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_clones(layer, N):\n",
    "    return [tf.keras.models.clone_model(layer) for _ in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "InpLayer = Input(shape=(Length, OrigDim,  ))\n",
    "\n",
    "## ConvEmbedding ##\n",
    "Embed  =  Conv1D(filters=EmbedDim, kernel_size=11, strides=1, padding='same', dilation_rate=1, input_shape=(None, OrigDim))(InpLayer)\n",
    "Embed = BatchNormalization(axis=-1, trainable=True, center=True, scale=True)(Embed)\n",
    "Embed = tf.transpose(Activation('relu')(Embed) , (0,2,1)) # shape [batch_size, embed_dim, length]\n",
    "## ConvEmbedding ##\n",
    "\n",
    "Embed =  tf.transpose(Embed, (2,0,1)) # shape [length, batch_size, embed_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EmbedOrgin = tf.identity(Embed)\n",
    "#Embed = tf.transpose(Embed, perm=[1, 0, 2])\n",
    "#Embed = self.bottleneck(Embed)\n",
    "\n",
    "#Embed = tf.transpose(Embed, perm=[2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = self.self_attn(Embed, pos_embed, return_attn_weights)\n",
    "q, k = self.q_k_conv(query.permute(1,2,0)).chunk(2, dim=1) # query should be [batch size, channel, length]\n",
    "# q_k_conv -> dilated_bottleneck_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLen, BatSize, EmbedDim = Embed.shape.as_list()\n",
    "HeadDim = EmbedDim // NumHead\n",
    "Scaling = float(HeadDim) ** -0.5\n",
    "\n",
    "Embed =  tf.transpose(Embed, perm=[1, 2, 0]) #query.permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 30000) dtype=float32 (created by layer 'tf.compat.v1.transpose_15')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dilated_bottleneck_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif firstlayergroups:\\n    dilated_conv = Conv1D( filters=out_channel,  kernel_size=kernel_size, dilation_rate=dilation,   padding='same',     groups=firstlayergroups  )(Embed) + tf.tile(Embed, [1,2,1])\\nelse:\\n    dilated_conv = Conv1D( filters=out_channel,  kernel_size=kernel_size, dilation_rate=dilation,   padding='same',    groups=groups )(Embed)\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self.bottle = tf.keras.layers.Conv1D(filters=bottleneck,   kernel_size=1,    groups=groups)\n",
    "Bottle = Conv1D(filters=Bottleneck,   kernel_size=1,    groups=groups)\n",
    "Embed = Conv1D(filters=Bottleneck,   kernel_size=1,    groups=groups)(Embed)\n",
    "firstlayergroups = groups\n",
    "# ReLU activation function\n",
    "Embed = Activation('relu')(Embed)\n",
    "# Batch normalization layer\n",
    "Embed = BatchNormalization(axis=-1, trainable=True, center=True, scale=True)(Embed)\n",
    "\n",
    "'''\n",
    "if firstlayergroups:\n",
    "    dilated_conv = Conv1D( filters=out_channel,  kernel_size=kernel_size, dilation_rate=dilation,   padding='same',     groups=firstlayergroups  )(Embed) + tf.tile(Embed, [1,2,1])\n",
    "else:\n",
    "    dilated_conv = Conv1D( filters=out_channel,  kernel_size=kernel_size, dilation_rate=dilation,   padding='same',    groups=groups )(Embed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 200, 32) dtype=float32 (created by layer 'tf.tile')>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.repeat(x, repeats=[2], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
